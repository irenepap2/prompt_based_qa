Task1-what was the baseline?_1,Task1-what was the baseline?_2,Task1-what was the baseline?_3,Task1-what was the baseline?_4,Task1-what dataset was used?_1,Task1-what dataset was used?_2,Task1-what dataset was used?_3,Task1-what dataset was used?_4,Task1-What dataset do they use?_1,Task1-What dataset do they use?_2,Task1-What dataset do they use?_3,Task1-What dataset do they use?_4,Task1-Which dataset do they use?_1,Task1-Which dataset do they use?_2,Task1-Which dataset do they use?_3,Task1-Which dataset do they use?_4,Task1-what are the baselines?_1,Task1-what are the baselines?_2,Task1-what are the baselines?_3,Task1-what are the baselines?_4,Task1-Which datasets do they evaluate on?_1,Task1-Which datasets do they evaluate on?_2,Task1-Which datasets do they evaluate on?_3,Task1-Which datasets do they evaluate on?_4,Task1-what were the evaluation metrics?_1,Task1-what were the evaluation metrics?_2,Task1-what were the evaluation metrics?_3,Task1-what were the evaluation metrics?_4,Task1-How long is their dataset?_1,Task1-How long is their dataset?_2,Task1-How long is their dataset?_3,Task1-How long is their dataset?_4,Task1-Do they report results only on English data?_1,Task1-Do they report results only on English data?_2,Task1-Do they report results only on English data?_3,Task1-Do they report results only on English data?_4,Task1-What datasets are used?_1,Task1-What datasets are used?_2,Task1-What datasets are used?_3,Task1-What datasets are used?_4,Task1-What are the baseline models?_1,Task1-What are the baseline models?_2,Task1-What are the baseline models?_3,Task1-What are the baseline models?_4,Task1-How long is the dataset?_1,Task1-How long is the dataset?_2,Task1-How long is the dataset?_3,Task1-How long is the dataset?_4,Task2-what was the baseline?_1_1,Task2-what was the baseline?_2_1,Task2-what was the baseline?_3_1,Task2-what was the baseline?_4_1,Task2-what dataset was used?_1_1,Task2-what dataset was used?_2_1,Task2-what dataset was used?_3_1,Task2-what dataset was used?_4_1,Task2-What dataset do they use?_1_1,Task2-What dataset do they use?_2_1,Task2-What dataset do they use?_3_1,Task2-What dataset do they use?_4_1,Task2-Which dataset do they use?_1_1,Task2-Which dataset do they use?_2_1,Task2-Which dataset do they use?_3_1,Task2-Which dataset do they use?_4_1,Task2-what are the baselines?_1_1,Task2-what are the baselines?_2_1,Task2-what are the baselines?_3_1,Task2-what are the baselines?_4_1,Task2-Which datasets do they evaluate on?_1_1,Task2-Which datasets do they evaluate on?_2_1,Task2-Which datasets do they evaluate on?_3_1,Task2-Which datasets do they evaluate on?_4_1,Task2-what were the evaluation metrics?_1_1,Task2-what were the evaluation metrics?_2_1,Task2-what were the evaluation metrics?_3_1,Task2-what were the evaluation metrics?_4_1,Task2-How long is their dataset?_1_1,Task2-How long is their dataset?_2_1,Task2-How long is their dataset?_3_1,Task2-How long is their dataset?_4_1,Task2-Do they report results only on English data?_1_1,Task2-Do they report results only on English data?_2_1,Task2-Do they report results only on English data?_3_1,Task2-Do they report results only on English data?_4_1,Task2-What datasets are used?_1_1,Task2-What datasets are used?_2_1,Task2-What datasets are used?_3_1,Task2-What datasets are used?_4_1,Task2-What are the baseline models?_1_1,Task2-What are the baseline models?_2_1,Task2-What are the baseline models?_3_1,Task2-What are the baseline models?_4_1,Task2-How long is the dataset?_1_1,Task2-How long is the dataset?_2_1,Task2-How long is the dataset?_3_1,Task2-How long is the dataset?_4_1
Weka,Numerical Features,Unanswerable,"PBMT-R, SBMT",Various emotions dataset,A self made linked noise and EEG,Published IEEE papers,Snap Amazon dataset,They use 2 datasets. The first one is for sentence extraction which labels sentences from news articles that must appear in the corresponding summary and the other one is for word extraction with words that appear in both the article and the highlight,They use 2 datasets. 1 dataset where chat sessions are manually annotated as the ground truth and 1 more unlabeled dataset to test their framework on,The English portion of CoNLL 2012 data,A dataset containing different vulnerabilities in code commits,Clueweb09 and a generated one crawling Wikipedia,Data from a survey and handcrafted questions,GlobalPhone,Tweets annotated by Potthast et al,"standard bididrectional RNN model with attention, a standard context agnostic Transformer.",one-stage RNN system,the methods suggested in Dori-Hacohen et al. (2016); Rad and Barbosa (2012),The original ESIM model,FIGER (GOLD) and BBN,SICK (Sentences Involving Compositional Knowledge),Open Minds Indoor Common Sense (OMICS) corpus,NIST 2006 (NIST06),Accuracy and the custom error metric defined in equation (1),"Avg. Recall, Accuracy and F-score","F-score, micro-averaged F-score",4-gram BLEU score,"Some tweets were not assigned labels as there was no majority class. This results in a sample of 24,802 labeled tweets",Unanswerable,"After removing documents with missing PDF files and documents which were not converted successfully, we were left with 624 full text documents","The train set contained 20214 sentence pairs, while the validation contained 1000 sentence pairs",Yes,Unanswerable,No,Yes,Craigslist Bargaining dataset (CB),PDTB 2.05,"(1) human-human utterances from massive online forums, microblogs, and question-answering communities, such as Sina Weibo Baidu Zhidao and Baidu Tieba, (2) dataset from various resources in public websites comprising 1,606,741 query-reply pairs.","Speech recording of patients in (1) Spanish (PC-GITA corpus), (2) German, (3) Czech","Baseline-BiLSTM, CRF-BiLSTM, Cross-BiLSTM-CNN and AttBiLSTM-CNN","MLE model and Baseline+(t), where t âˆˆ [0, 1]","ELMo, USE, NBSVM, FastText, XLnet base cased model (XLnet), BERT in two setups: BERT base cased (BERT-Cased) and BERT base uncased (BERT-Uncased) models, and RoBERTa base model",Transformer baseline,330M,6381+7527+5424 = 19332 reviews,98976 tokens,3045+2000 = 5045 sentences in training set and 800+676 = 1476 in test set,Weka baseline,Unanswerable,Bing Liu's Dataset,Hybrid â€“ the current state-of-the-art,"The training, validation and test datasets provided for the shared task BIBREF5",Data set A and Data set B,113 GB,Bing Liu's dataset,DUC 2002 document summarization corpus and DailyMail news highlights corpus,"The dataset was crawled from the Douban forum, containing 3 million utterances and approximately 150,000 unique words (Chinese terms).",The English portion of CoNLL 2012 data,Manually-curated dataset of publicly disclosed vulnerabilities in 205 distinct open-source Java projects mapped to commits fixing them,Clueweb09 derived dataset and Wikipedia crawl data,U.S. Census Bureau conducted Annual Retail Trade Survey of U.S. Retail and Food Services Firms for the period of 1992 to 2013,"GlobalPhone corpus, zrsc 2015, Buckeye corpus, NCHLT corpus, English wsj corpus",BIBREF4 crowdsourced the annotation of 19538 tweets they had curated,"a standard bidirectional RNN model with attention, a standard context-agnostic Transformer, and a recurrent baseline",a one-stage RNN system,"Nearest neighbors (NN) Estimator, Naive Bayes (NB) Estimator and Recurrent neural network (RNN)",ESIM MODEL,FIGER (GOLD) and BBN,SICK (Sentences Involving Compositional Knowledge) dataset,Open Minds Indoor Common Sense (OMICS),"NIST OpenMT08 task, NIST 2006 (NIST06) dataset, NIST 2002 (NIST02), 2003 (NIST03), 2004 (NIST04) 2005 (NIST05), and 2008 (NIST08) datasets",cost measure that uses the confusion matrix of the prediction and prior knowledge,macro-average recall,"F-score for class 1 (ADR): INLINEFORM0, micro-averaged F-score of the class 1 (intake) and class 2 (possible intake): INLINEFORM0 INLINEFORM1, total score = INLINEFORM0",case-insensitive 4-gram BLEU score and faithfulness of translation results (scored 0-5),85.4 million tweets,29044,624 full text documents,23315 sentence pairs,No,Yes,Yes,Yes,Craigslist Bargaining dataset (CB),PDTB 2.0,"A dataset of 1,606,741 query-reply pairs and a dataset of human-human utterance pairs","Spanish, German, and Czech",BiLSTM-CNN proposed by BIBREF1,"MLE model and Baseline$+(t)$ with $t \in [0,1]$","ELMo, USE, NBSVM, FastText, XLnet base cased model (XLnet), BERT base cased (BERT-Cased) and BERT base uncased (BERT-Uncased) models, and RoBERTa base model",Seq2Seq MT models,"12,284 English-language tweets and 6100 Arabic-language tweets",5000 for each TV series,"5,124 sentences",Unanswerable